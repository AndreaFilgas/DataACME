{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import warnings\n",
    "import string\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv('C:/Users/camil/Desktop/Projeto Integrador/dados/rotten_imdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar copias dos dois datasets para manipular os dados\n",
    "df = df_csv.copy()\n",
    "#df2 = dfx.copy()\n",
    "\n",
    "# excluir linhas repetidas\n",
    "df.drop_duplicates(subset = 'movie_info', inplace = True)\n",
    "\n",
    "# remover os filmes que nao tem avg_rating\n",
    "df.dropna(subset = ['tomatometer_avg_rating'], inplace = True)\n",
    "\n",
    "# selecionar colunas de interesse dos dois datasets\n",
    "df = df[['tconst','movie_name_imdb', 'directors','casts','movie_info','genres']]\n",
    "#df2 = df2[['tconst','movie_name_imdb', 'directors','casts','movie_info','genres']]\n",
    "\n",
    "# excluir missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# juntar os dois datasets\n",
    "#df.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remoção da pontuação de 'Plot'\n",
    "df['movie_info'] = df['movie_info'].str.replace('[{}]'.format(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # inicialização das lista que será a nova coluna\n",
    "df['Key_words'] = ''  \n",
    "\n",
    "# instanciação do objeto do Rake para descartar as 'stop words' (baseado naquilo que está no NLTK)\n",
    "r = Rake()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # extração das key words - que já remove as 'stop words' do texto\n",
    "    r.extract_keywords_from_text(row['movie_info'])   \n",
    "    # dicionário com as key words e scores\n",
    "    key_words_dict_scores = r.get_word_degrees()    \n",
    "    # nova coluna que será inserida\n",
    "    row['Key_words'] = list(key_words_dict_scores.keys())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to extract all genre into a list, only the first three actors into a list, and all directors into a list\n",
    "df['genres'] = df['genres'].map(lambda x: x.split(','))\n",
    "df['directors'] = df['directors'].map(lambda x: x.split(','))\n",
    "df['casts'] = df['casts'].map(lambda x: x.split(',')[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retirada dos espaços dos campos e conversão para minúsculas\n",
    "for index, row in df.iterrows():\n",
    "    row['genres'] = [x.lower().replace(' ','') for x in row['genres']]\n",
    "    row['casts'] = [x.lower().replace(' ','') for x in row['casts']]\n",
    "    row['directors'] = [x.lower().replace(' ','') for x in row['directors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicialização da lista\n",
    "df['Bag_of_words'] = ''\n",
    "# colunas que farão parte da Bag of Words\n",
    "columns = ['genres', 'directors', 'casts', 'Key_words']\n",
    "# percorre cada coluna e adiciona cada palavra individualmente\n",
    "for index, row in df.iterrows():\n",
    "    words = ''\n",
    "    for col in columns:\n",
    "        words += ' '.join(row[col]) + ' '\n",
    "    row['Bag_of_words'] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remoção dos \"espaços\" de todas as palavras na BoW\n",
    "df['Bag_of_words'] = df['Bag_of_words'].str.strip().str.replace('   ', ' ').str.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bag = df[['tconst','movie_name_imdb','Bag_of_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração da Matriz com a frequência de cada palavra com filme 250 x quantidade total de palavras únicas\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(df_bag['Bag_of_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create a Series for movie titles which can be used as indices (each index is mapped to a movie title)\n",
    "indices = pd.Series(df_bag['movie_name_imdb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(title, cosine_sim = cosine_sim):\n",
    "    # inicialização da lista\n",
    "    recommended_movies = []\n",
    "    # captura o índice que corresponde ao título\n",
    "    idx = indices[indices == title].index[0]   \n",
    "    # scores de similaridade em ordem descendente\n",
    "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)   \n",
    "    # captura os 10 filmes com o maior índice de similaridade\n",
    "    top_10_indices = list(score_series.iloc[1:11].index)   \n",
    "    # [1:11] para excluir o primeiro (0) que é o próprio filme selecionado\n",
    "    \n",
    "    # monta uma lista com os filmes retornados\n",
    "    for i in top_10_indices:   \n",
    "        recommended_movies.append(list(df_bag['movie_name_imdb'])[i])\n",
    "        \n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filme = recommend('Elf')\n",
    "\n",
    "# recomendacao para o filme que sera produzido\n",
    "#filme = recommend(df2.movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.95"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(df_csv.tomatometer_avg_rating[df_csv.movie_name_imdb == filme[0]])\n",
    "\n",
    "# pegar a rating_avg desse filme mais proximo e salvar como uma nova coluna para o filme a ser feito\n",
    "#df_x['rating_avg'] = float(df.tomatometer_avg_rating[df.movie_name_imdb == filme])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
